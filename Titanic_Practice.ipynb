{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10695,"sourceType":"datasetVersion","datasetId":7519},{"sourceId":8917134,"sourceType":"datasetVersion","datasetId":5362767}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-21T16:08:47.569234Z","iopub.execute_input":"2024-07-21T16:08:47.570146Z","iopub.status.idle":"2024-07-21T16:08:47.585680Z","shell.execute_reply.started":"2024-07-21T16:08:47.570103Z","shell.execute_reply":"2024-07-21T16:08:47.584068Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"/kaggle/input/rb-titanic/train.csv\n/kaggle/input/rb-titanic/test.csv\n/kaggle/input/titanic/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/rb-titanic/train.csv\")\nprint(df)\nprint(df.info())\nprint(\"\\nDescriptive statistics:\")\nprint(df.describe())\n\n# Check for missing values\nprint(\"\\nMissing values:\")\nprint(df.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:08:47.588200Z","iopub.execute_input":"2024-07-21T16:08:47.588604Z","iopub.status.idle":"2024-07-21T16:08:47.642841Z","shell.execute_reply.started":"2024-07-21T16:08:47.588572Z","shell.execute_reply":"2024-07-21T16:08:47.641423Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\nNone\n\nDescriptive statistics:\n       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  \n\nMissing values:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n#import polars as pl\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, FunctionTransformer, PowerTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n# Notes: PCA didn't help!?\n####\n# NEXT STEPS: internally split the data into a sub-test so we can iterate faster!\n# MAKE SUBMISSION A SECOND SECTION?\n\nversion = 12\nname = \"pca_95_sibs_parents\"\n\nFINAL_TEST = True\nPCA_PERCENT = 95  # EXPERIMENTS = range(50, 76, 1)\nif FINAL_TEST:\n    EXPERIMENTS = [PCA_PERCENT] if FINAL_TEST else EXPERIMENTS\nelse:\n    EXPERIMENTS = range(50, 99, 2)\n\n#DROP_FEATURES = [\"PassengerId\", \"Survived\", \"Pclass\", \"Name\", \"Ticket\", \"Fare\", \"Cabin\"]\nLABEL = [\"Survived\"]\nSCALED_FEATURES = [\"Age\", \"SibSp\", \"Parch\"]  # Fare did not seem to improve\nCAT_FEATURES = [\"Embarked\", \"Pclass\"]\nBOOL_FEATURES = [\"Sex\"]\n\ndef make_pipeline(pca_percent=PCA_PERCENT):\n    print(pca_percent)\n    # Create the preprocessing steps for specific column processing\n    preprocessor = ColumnTransformer(\n        transformers=[\n            (\n                'num',\n                Pipeline(steps=\n                    [\n                        ('average', SimpleImputer(missing_values=np.nan, strategy='mean')),\n                        ('scale', StandardScaler()),\n                    ],\n                ),\n                 SCALED_FEATURES,\n            ),\n            (\n                'cat',\n                Pipeline(steps=\n                    [\n                        ('imputer', SimpleImputer(strategy='most_frequent')),\n                        ('onehot', OneHotEncoder(handle_unknown='ignore', drop=\"first\", sparse_output=False))\n                    ],\n                ),\n                CAT_FEATURES + BOOL_FEATURES,\n            ),\n        ],\n        remainder=\"drop\",\n    )\n\n    # Create the full pipeline\n    pipeline = Pipeline([\n        ('preprocess', preprocessor),\n        ('pca', PCA(n_components=pca_percent/100)),\n        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42)),\n    ])\n    \n    return pipeline\n\n# Get train/test features and labels\ndf = pd.read_csv(\"/kaggle/input/rb-titanic/train.csv\")\nX = df.drop(LABEL, axis=1)\ny = df[LABEL]\ny = y.values.ravel()\nif FINAL_TEST:\n    X_train = X\n    y_train = y\n    X_test = pd.read_csv(\"/kaggle/input/rb-titanic/test.csv\")\n    # NOTE: There is no y_test in the final\nelse:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n\nfor experiment in EXPERIMENTS:\n    # Train with pipeline\n    pipeline = make_pipeline(experiment)\n    pipeline.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    y_pred = pipeline.predict(X_test)\n\n    # Evaluate the model\n    if not FINAL_TEST:\n        print(f\"{version}_{name} SCORES\")\n        mse = mean_squared_error(y_test, y_pred)  # <-- NO y_test/Survived IN DATA. Submit?\n        rmse = np.sqrt(mse)\n        print(f\"RMSE:\\t{rmse}\")\n        r2 = r2_score(y_test, y_pred)\n        print(f\"R2:\\t{r2}\")\n        accuracy = accuracy_score(y_test, y_pred)\n        print(f\"Acc:\\t{accuracy}\")\n        from sklearn.metrics import f1_score\n        f1 = f1_score(y_test, y_pred)\n        print(f\"F1:\\t{f1}\")\n        print(\"---\")\n\n    # Save the final test results\n    else:\n        # Save the DataFrame to a CSV file\n        results_df = pd.DataFrame({\n            \"PassengerId\": X_test[\"PassengerId\"],\n            \"Survived\": y_pred,\n        })\n        print(results_df)\n\n        csv_filename = f\"titanic_restart_{version}_{name}.csv\"\n        results_df.to_csv(csv_filename, index=False)\n        print(f\"Predictions saved to {csv_filename}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:22:16.332910Z","iopub.execute_input":"2024-07-21T16:22:16.333426Z","iopub.status.idle":"2024-07-21T16:22:16.806592Z","shell.execute_reply.started":"2024-07-21T16:22:16.333389Z","shell.execute_reply":"2024-07-21T16:22:16.805068Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"95\n     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         1\n4            896         0\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         1\n\n[418 rows x 2 columns]\nPredictions saved to titanic_restart_11_pca_95_fare.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}